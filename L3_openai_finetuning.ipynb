{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486578c6-5684-457e-91db-9dce41084c14",
   "metadata": {},
   "source": [
    "# L3: Fine-Tuning with OpenAI\n",
    "\n",
    "## Why OpenAI Instead of Google Cloud\n",
    "\n",
    "After attempting Google Cloud Vertex AI in `L3_automation.ipynb`, encountered:\n",
    "- API deprecation (text-bison)\n",
    "- Regional limitations (Gemini not available)\n",
    "- 3+ hours of debugging\n",
    "\n",
    "OpenAI provides:\n",
    "- Immediate access\n",
    "- Same JSONL format (our data works as-is!)\n",
    "- Reliable service\n",
    "-Better documentation\n",
    "\n",
    "## What We're Doing\n",
    "Fine-tuning GPT-4o-mini on our 10,000 Stack Overflow Python Q&As\n",
    "\n",
    "## Cost\n",
    "- Training: ~$6-8\n",
    "- Free credit: -$5\n",
    "- **Your cost: ~$1-3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cfb18-84d8-4f1f-997b-6cd4e5d7f3ba",
   "metadata": {},
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28add145-07d5-4429-ba86-06397fd81b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI initialized\n",
      "Key: sk-proj-c4JHt8PTD-Go...\n"
     ]
    }
   ],
   "source": [
    "# L3: OpenAI Fine-Tuning Setup\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"OpenAI initialized\")\n",
    "print(f\"Key: {openai.api_key[:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc28129-1e65-4b09-922e-35662386e5fb",
   "metadata": {},
   "source": [
    "CELL 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ecad82a-c14e-479a-a109-9457328bace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREATING TINY DATASET (100 EXAMPLES)\n",
      "======================================================================\n",
      "\n",
      "Cost comparison:\n",
      "‚îú‚îÄ‚îÄ 7,200 examples: $55\n",
      "‚îú‚îÄ‚îÄ 500 examples: $4\n",
      "‚îî‚îÄ‚îÄ 100 examples: $0.50-$1.50 ‚úÖ\n",
      "\n",
      "‚úÖ Training set: 100 examples\n",
      " Evaluation set: 20 examples\n",
      "\n",
      "======================================================================\n",
      " TINY DATASET READY!\n",
      "======================================================================\n",
      "\n",
      "Estimated cost: $0.50 - $1.50\n",
      "This will DEFINITELY fit your $3.38 budget!\n",
      "\n",
      "Note: 100 examples is small but still useful!\n",
      "Many models are fine-tuned on 100-200 examples.\n"
     ]
    }
   ],
   "source": [
    "# Create even smaller dataset (100 examples - super cheap!)\n",
    "import json\n",
    "\n",
    "def create_smaller_dataset(input_file, output_file, n_examples):\n",
    "    \"\"\"Take only first N examples\"\"\"\n",
    "    count = 0\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        for line in infile:\n",
    "            if count >= n_examples:\n",
    "                break\n",
    "            outfile.write(line)\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CREATING TINY DATASET (100 EXAMPLES)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nCost comparison:\")\n",
    "print(\"‚îú‚îÄ‚îÄ 7,200 examples: $55\")\n",
    "print(\"‚îú‚îÄ‚îÄ 500 examples: $4\")\n",
    "print(\"‚îî‚îÄ‚îÄ 100 examples: $0.50-$1.50 ‚úÖ\")\n",
    "print()\n",
    "\n",
    "# Create tiny training set (100 examples)\n",
    "train_count = create_smaller_dataset(\n",
    "    \"tune_data_stack_overflow_python_qa.jsonl\", \n",
    "    \"tune_data_tiny.jsonl\", \n",
    "    100\n",
    ")\n",
    "print(f\"‚úÖ Training set: {train_count} examples\")\n",
    "\n",
    "# Create tiny eval set (20 examples)\n",
    "eval_count = create_smaller_dataset(\n",
    "    \"tune_eval_stack_overflow_python_qa.jsonl\", \n",
    "    \"tune_eval_tiny.jsonl\", \n",
    "    20\n",
    ")\n",
    "print(f\" Evaluation set: {eval_count} examples\")\n",
    "\n",
    "# Update file paths for next cells\n",
    "TRAIN_FILE = \"tune_data_tiny.jsonl\"\n",
    "EVAL_FILE = \"tune_eval_tiny.jsonl\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" TINY DATASET READY!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nEstimated cost: $0.50 - $1.50\")\n",
    "print(\"This will DEFINITELY fit your $3.38 budget!\")\n",
    "print(\"\\nNote: 100 examples is small but still useful!\")\n",
    "print(\"Many models are fine-tuned on 100-200 examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047637b-ca85-40ef-a7d0-865fdcc1f05a",
   "metadata": {},
   "source": [
    "CHECK DATA FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e243a4a8-81b6-4d0b-a818-2dc3e42c7810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING DATA FILES\n",
      "======================================================================\n",
      "\n",
      " tune_data_stack_overflow_python_qa-20251214_102129.jsonl\n",
      "   Size: 37.23 MB\n",
      "   Examples: 8,000\n",
      "\n",
      " tune_data_stack_overflow_python_qa.jsonl\n",
      "   Size: 33.56 MB\n",
      "   Examples: 7,200\n",
      "\n",
      " tune_eval_stack_overflow_python_qa.jsonl\n",
      "   Size: 3.67 MB\n",
      "   Examples: 800\n",
      "\n",
      "======================================================================\n",
      "Will use: tune_data_stack_overflow_python_qa.jsonl\n",
      "Will use: tune_eval_stack_overflow_python_qa.jsonl\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Find JSONL files\n",
    "jsonl_files = glob.glob(\"*.jsonl\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING DATA FILES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for file in jsonl_files:\n",
    "    size = os.path.getsize(file) / (1024 * 1024)  # MB\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        lines = len(f.readlines())\n",
    "    \n",
    "    print(f\"\\n {file}\")\n",
    "    print(f\"   Size: {size:.2f} MB\")\n",
    "    print(f\"   Examples: {lines:,}\")\n",
    "\n",
    "# Set file paths\n",
    "TRAIN_FILE = \"tune_data_stack_overflow_python_qa.jsonl\"\n",
    "EVAL_FILE = \"tune_eval_stack_overflow_python_qa.jsonl\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Will use: {TRAIN_FILE}\")\n",
    "print(f\"Will use: {EVAL_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5949598-7ab2-46e3-ba2d-e1a83d193109",
   "metadata": {},
   "source": [
    "CONVERT TO OPENAI FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a2d0b08-ea8b-4a12-8593-0005a03255e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting training data...\n",
      "‚úÖ 100 training examples converted\n",
      "\n",
      "üîÑ Converting validation data...\n",
      "‚úÖ 20 validation examples converted\n",
      "\n",
      "======================================================================\n",
      "‚úÖ DATA READY FOR UPLOAD!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def convert_to_openai_format(input_file, output_file):\n",
    "    \"\"\"Convert to OpenAI messages format\"\"\"\n",
    "    converted = 0\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        for line in infile:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            openai_format = {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are a helpful Python expert who answers like Stack Overflow.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": data[\"input_text_instruct\"]\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": data[\"output_text\"]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            outfile.write(json.dumps(openai_format) + '\\n')\n",
    "            converted += 1\n",
    "    \n",
    "    return converted\n",
    "\n",
    "# Use the TINY files created in Cell 3.5\n",
    "TRAIN_FILE = \"tune_data_tiny.jsonl\"  # ‚Üê Changed to tiny!\n",
    "EVAL_FILE = \"tune_eval_tiny.jsonl\"    # ‚Üê Changed to tiny!\n",
    "\n",
    "print(\"üîÑ Converting training data...\")\n",
    "train_count = convert_to_openai_format(TRAIN_FILE, \"train_openai.jsonl\")\n",
    "print(f\"‚úÖ {train_count:,} training examples converted\")\n",
    "\n",
    "print(\"\\nüîÑ Converting validation data...\")\n",
    "eval_count = convert_to_openai_format(EVAL_FILE, \"eval_openai.jsonl\")\n",
    "print(f\"‚úÖ {eval_count:,} validation examples converted\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ DATA READY FOR UPLOAD!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9789d444-db78-4dd1-8c93-ebe834ed77b4",
   "metadata": {},
   "source": [
    "UPLOAD TO OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e07e17b-5815-4b12-b25b-541fa9f202b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "UPLOADING FILES TO OPENAI\n",
      "======================================================================\n",
      "\n",
      " This takes 2-3 minutes...\n",
      "\n",
      "1/2 Uploading training data (8,000 examples)...\n",
      "     Training file: file-W9XP7KVkdfT9cqg5Xz3DBL\n",
      "\n",
      "2/2 Uploading validation data (2,000 examples)...\n",
      "     Validation file: file-826aciiDurb8JuqB8X6fP3\n",
      "\n",
      "======================================================================\n",
      " FILES UPLOADED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"UPLOADING FILES TO OPENAI\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n This takes 2-3 minutes...\\n\")\n",
    "\n",
    "# Upload training\n",
    "print(\"1/2 Uploading training data (8,000 examples)...\")\n",
    "with open(\"train_openai.jsonl\", \"rb\") as f:\n",
    "    training_file = openai.files.create(\n",
    "        file=f,\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "print(f\"     Training file: {training_file.id}\")\n",
    "\n",
    "# Upload validation  \n",
    "print(\"\\n2/2 Uploading validation data (2,000 examples)...\")\n",
    "with open(\"eval_openai.jsonl\", \"rb\") as f:\n",
    "    validation_file = openai.files.create(\n",
    "        file=f,\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "print(f\"     Validation file: {validation_file.id}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" FILES UPLOADED SUCCESSFULLY!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30155a2c-c14c-4564-bec6-6cda93a22786",
   "metadata": {},
   "source": [
    " START FINE-TUNING! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f65bd8c-b437-4720-bb37-28ee38884719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " STARTING FINE-TUNING JOB\n",
      "======================================================================\n",
      "\n",
      " This will take 30-60 minutes...\n",
      "\n",
      " FINE-TUNING STARTED!\n",
      "\n",
      "======================================================================\n",
      "JOB DETAILS\n",
      "======================================================================\n",
      "\n",
      " Job ID: ftjob-F15zqv4WC6HSQWthkarxmgac\n",
      " Status: validating_files\n",
      " Base Model: gpt-4o-mini-2024-07-18\n",
      "\n",
      " Job ID saved to: finetuning_job_id.txt\n",
      "\n",
      "======================================================================\n",
      "WHAT HAPPENS NOW?\n",
      "======================================================================\n",
      "\n",
      " Training runs in the cloud (30-60 min)\n",
      " You can close this notebook\n",
      " OpenAI will email you when complete\n",
      " Check status anytime with Cell 7 below\n",
      " Cost: ~$6-8 (minus your $5 free credit!)\n",
      "\n",
      "NEXT STEPS:\n",
      "1. Wait for training to complete\n",
      "2. Run Cell 7 to check status\n",
      "3. When done, go to L4 to use your model!\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\" STARTING FINE-TUNING JOB\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n This will take 30-60 minutes...\\n\")\n",
    "\n",
    "fine_tuning_job = openai.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    suffix=\"stackoverflow-qa\"\n",
    ")\n",
    "\n",
    "print(\" FINE-TUNING STARTED!\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"JOB DETAILS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n Job ID: {fine_tuning_job.id}\")\n",
    "print(f\" Status: {fine_tuning_job.status}\")\n",
    "print(f\" Base Model: {fine_tuning_job.model}\")\n",
    "\n",
    "# Save job ID\n",
    "with open(\"finetuning_job_id.txt\", \"w\") as f:\n",
    "    f.write(fine_tuning_job.id)\n",
    "\n",
    "print(\"\\n Job ID saved to: finetuning_job_id.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"WHAT HAPPENS NOW?\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    " Training runs in the cloud (30-60 min)\n",
    " You can close this notebook\n",
    " OpenAI will email you when complete\n",
    " Check status anytime with Cell 7 below\n",
    " Cost: ~$6-8 (minus your $5 free credit!)\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Wait for training to complete\n",
    "2. Run Cell 7 to check status\n",
    "3. When done, go to L4 to use your model!\n",
    "\"\"\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f3ce1-95a2-4596-aa08-353c27e6fea2",
   "metadata": {},
   "source": [
    "CHECK STATUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9a96096-dd7c-4ac8-a535-d8caa3d8fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checking training status...\n",
      "\n",
      "======================================================================\n",
      "FINE-TUNING STATUS\n",
      "======================================================================\n",
      "\n",
      " Job ID: ftjob-F15zqv4WC6HSQWthkarxmgac\n",
      " Status: validating_files\n",
      " Base Model: gpt-4o-mini-2024-07-18\n",
      "\n",
      " Current status: validating_files\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check fine-tuning status\n",
    "# Run this cell anytime to see progress!\n",
    "\n",
    "print(\" Checking training status...\\n\")\n",
    "\n",
    "try:\n",
    "    with open(\"finetuning_job_id.txt\", \"r\") as f:\n",
    "        job_id = f.read().strip()\n",
    "    \n",
    "    job = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"FINE-TUNING STATUS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\n Job ID: {job.id}\")\n",
    "    print(f\" Status: {job.status}\")\n",
    "    print(f\" Base Model: {job.model}\")\n",
    "    \n",
    "    if job.status == \"succeeded\":\n",
    "        print(\"\\n\" + \" \" * 35)\n",
    "        print(\"TRAINING COMPLETE!\")\n",
    "        print(\" \" * 35)\n",
    "        print(f\"\\n‚úÖ Your fine-tuned model: {job.fine_tuned_model}\")\n",
    "        \n",
    "        # Save model name\n",
    "        with open(\"finetuned_model_name.txt\", \"w\") as f:\n",
    "            f.write(job.fine_tuned_model)\n",
    "        \n",
    "        print(\"\\n Model name saved to: finetuned_model_name.txt\")\n",
    "        print(\"\\n NEXT STEP: Go to L4_predictions.ipynb!\")\n",
    "        print(\"   1. Restart kernel\")\n",
    "        print(\"   2. Run from Cell 13\")\n",
    "        print(\"   3. Your custom model will load automatically!\")\n",
    "        \n",
    "    elif job.status == \"running\":\n",
    "        print(\"\\n Training in progress...\")\n",
    "        print(\"   Check back in 10-15 minutes!\")\n",
    "        print(\"   Or wait for email notification\")\n",
    "        \n",
    "    elif job.status == \"failed\":\n",
    "        print(\"\\n Training failed!\")\n",
    "        print(f\"   Error: {job.error}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n Current status: {job.status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\" finetuning_job_id.txt not found!\")\n",
    "    print(\"   Did you run Cell 6 to start training?\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ded32e1-0039-40a6-846c-13f93106e33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ERROR DETAILS\n",
      "======================================================================\n",
      "\n",
      "üìç Job ID: ftjob-F15zqv4WC6HSQWthkarxmgac\n",
      "üìä Status: validating_files\n",
      "\n",
      "‚ùå Error Code: None\n",
      "‚ùå Error Message: None\n",
      "‚ùå Error Param: None\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get detailed error information\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "with open(\"finetuning_job_id.txt\", \"r\") as f:\n",
    "    job_id = f.read().strip()\n",
    "\n",
    "job = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ERROR DETAILS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìç Job ID: {job.id}\")\n",
    "print(f\"üìä Status: {job.status}\")\n",
    "\n",
    "if job.error:\n",
    "    print(f\"\\n‚ùå Error Code: {job.error.code}\")\n",
    "    print(f\"‚ùå Error Message: {job.error.message}\")\n",
    "    print(f\"‚ùå Error Param: {job.error.param}\")\n",
    "else:\n",
    "    print(\"\\nNo error details available\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e1c1545-8ccb-4afa-b639-cfb4adfdbbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CHECKING TRAINING FILE\n",
      "======================================================================\n",
      "\n",
      "‚úÖ File exists\n",
      "‚úÖ Total lines: 100\n",
      "\n",
      "üìÑ First example structure:\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful Python expert who answers like Stack Overflow.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Please answer the following Stackoverflow question on Python.\\nAnswer it like you are a developer answering Stackoverflow questions.\\n\\nStackoverflow question:\\nMLFlow active run does not match environment run id<p>I am trying to perform an MLFlow run but stuck with the following error after trying a lot of things\n",
      "\n",
      "üîç Validation checks:\n",
      "\n",
      "‚úÖ First 10 lines look valid\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check if files were validated properly\n",
    "import openai\n",
    "\n",
    "# Get training file details\n",
    "print(\"=\" * 70)\n",
    "print(\"CHECKING TRAINING FILE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    with open(\"train_openai.jsonl\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    print(f\"\\n‚úÖ File exists\")\n",
    "    print(f\"‚úÖ Total lines: {len(lines)}\")\n",
    "    \n",
    "    # Check first example\n",
    "    import json\n",
    "    first = json.loads(lines[0])\n",
    "    \n",
    "    print(\"\\nüìÑ First example structure:\")\n",
    "    print(json.dumps(first, indent=2)[:500])\n",
    "    \n",
    "    # Check for common issues\n",
    "    print(\"\\nüîç Validation checks:\")\n",
    "    \n",
    "    for i, line in enumerate(lines[:10]):  # Check first 10\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Check required fields\n",
    "            if \"messages\" not in data:\n",
    "                print(f\"‚ùå Line {i+1}: Missing 'messages' field\")\n",
    "            else:\n",
    "                msgs = data[\"messages\"]\n",
    "                if len(msgs) < 2:\n",
    "                    print(f\"‚ùå Line {i+1}: Need at least 2 messages\")\n",
    "                    \n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"‚ùå Line {i+1}: Invalid JSON\")\n",
    "    \n",
    "    print(\"\\n‚úÖ First 10 lines look valid\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa9a32-4b87-4365-9b5a-857d7dc9e481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (vertex-ai-env)",
   "language": "python",
   "name": "vertex-ai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
